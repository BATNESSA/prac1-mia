# -*- coding: utf-8 -*-
"""Tokenizador.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18h1nzn5F0Z__eKP5qLRmaZUeC7YEvEYD
"""
import nltk
nltk.download("popular")


from nltk.tokenize import word_tokenize
#Este método funciona para multiples idiomas pero no elimina los signos de puntuación
EJEMPLO_PALABRAS = "Hola, mi nombre es Pepe."
word_tokenize(EJEMPLO_PALABRAS)
EJEMPLO_PALABRAS.split()
print (EJEMPLO_PALABRAS.split())
print (word_tokenize("Hola, mi nombre es Pepe."))

from nltk.tokenize import sent_tokenize
EJEMPLO_FRASES = "Hola, mi nombre es Pepe. Mi casa no estoy seguro de dónde está."
sent_tokenize(EJEMPLO_FRASES)
print (sent_tokenize(EJEMPLO_FRASES))

frases=EJEMPLO_FRASES.split(".")
print (frases) #frases[:len(frases)-1]
print (frases[0].strip())
print (frases[1].strip())
print (frases[2].strip())
frases[1].strip()